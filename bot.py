import logging
import openai
from telegram import Update
from telegram.ext import ApplicationBuilder, ContextTypes, CommandHandler, MessageHandler, filters

# –í–°–¢–ê–í–¨ –°–Æ–î–ê –°–í–û–ò –ö–õ–Æ–ß–ò (–Ω–æ Railway —Å–∞–º –∏—Ö –ø–æ–¥—Å—Ç–∞–≤–∏—Ç)
import os
TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

openai.api_key = OPENAI_API_KEY
logging.basicConfig(level=logging.INFO)

# –°—Ç–∞—Ä—Ç–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("–ü—Ä–∏–≤–µ—Ç! –Ø –±–æ—Ç –î–∞–º–∏—Ä–∞. –ü–∏—à–∏ —á—Ç–æ —É–≥–æ–¥–Ω–æ ‚Äî –ø–æ–±–æ–ª—Ç–∞–µ–º üôÇ")

# –û—Ç–≤–µ—Ç –Ω–∞ –ª—é–±–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_message = update.message.text
    chat_id = update.message.chat_id

    try:
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "–¢—ã ‚Äî –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π, –ø—Ä–æ—Å—Ç–æ–π, –Ω–µ–º–Ω–æ–≥–æ —à—É—Ç–ª–∏–≤—ã–π —Å–æ–±–µ—Å–µ–¥–Ω–∏–∫. –û—Ç–≤–µ—á–∞–π –∫–∞–∫ –±—É–¥—Ç–æ —Ç—ã –î–∞–º–∏—Ä, –≤—Å–µ–≥–¥–∞ –≤–µ–∂–ª–∏–≤–æ –∏ —Å —Ç–µ–ø–ª–æ—Ç–æ–π."},
                {"role": "user", "content": user_message}
            ]
        )
        reply = response.choices[0].message.content.strip()
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ OpenAI: {e}")
        reply = "–û–π, —á—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫. –ü–æ–ø—Ä–æ–±—É–π –ø–æ–∑–∂–µ!"

    await context.bot.send_message(chat_id=chat_id, text=reply)

# –ó–∞–ø—É—Å–∫
if __name__ == '__main__':
    app = ApplicationBuilder().token(TELEGRAM_TOKEN).build()
    app.add_handler(CommandHandler("start", start))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
    app.run_polling()
